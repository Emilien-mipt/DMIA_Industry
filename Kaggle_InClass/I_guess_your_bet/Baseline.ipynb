{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import  model_selection, linear_model\n",
    "from sklearn.metrics import mean_squared_log_error, recall_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(est, x, y_test):\n",
    "    \"\"\"\n",
    "    Метрика rmsle\n",
    "\n",
    "    :est: обученный экземпляр модели\n",
    "    :x: объекты на которых нужно предсказать значение\n",
    "    :y_test: фактическое значение объектов\n",
    "    :returns: значение метрики rmsle на выборке x\n",
    "    \"\"\"\n",
    "\n",
    "    predict = est.predict(x)\n",
    "    predict = [x if x > 0 else 0 for x in predict]\n",
    "    return np.sqrt(mean_squared_log_error(y_test, predict ))\n",
    "\n",
    "\n",
    "def regr_score(x_train, y_train, regr, scoring):\n",
    "    \"\"\"\n",
    "    Расчет кроссвалидации и вывод на экран\n",
    "\n",
    "    :x_train: обучающая выборка\n",
    "    :y_train: целевое значение\n",
    "    :regr: экземпляр модели\n",
    "    :scoring: метрика\n",
    "    \"\"\"\n",
    "    scores = cross_validate(regr, \n",
    "                            x_train, \n",
    "                            y_train, \n",
    "                            scoring=scoring,\n",
    "                            cv=5, \n",
    "                            return_train_score=False)\n",
    "    \n",
    "    scores_list = scores[list(scores.keys())[-1]]\n",
    "    print(scores_list)\n",
    "    print(f'mean score -- {np.mean(scores_list)}')\n",
    "    \n",
    "    \n",
    "def get_data():\n",
    "    df_x = pd.read_csv(f'{data_dir}/train.csv')\n",
    "    df_x = df_x.fillna(-1)\n",
    "        \n",
    "    y = df_x['label']\n",
    "    df_x = df_x.drop(['label', 'status', 'short', 'activity_title', 'title_activity_type',\n",
    "                      'activity_description', 'title_direction', 'comment_direction'], \n",
    "                     axis=1)\n",
    "    return df_x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{data_dir}/train.csv')\n",
    "df = df.fillna(-1)\n",
    "df = df.drop(['status', 'short', 'activity_title', 'title_activity_type', 'activity_description', \n",
    "                  'title_direction', 'comment_direction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13000, 11)\n",
      "13000\n",
      "Index(['id_bet', 'run_id', 'user_id', 'direction_id', 'activity_id',\n",
      "       'size_max', 'size_min', 'is_educational', 'is_checkin_required',\n",
      "       'activity_type_id', 'main_competence_id'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_bet</th>\n",
       "      <th>run_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>size_max</th>\n",
       "      <th>size_min</th>\n",
       "      <th>is_educational</th>\n",
       "      <th>is_checkin_required</th>\n",
       "      <th>activity_type_id</th>\n",
       "      <th>main_competence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>790</td>\n",
       "      <td>844</td>\n",
       "      <td>3.0</td>\n",
       "      <td>358</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>135</td>\n",
       "      <td>898</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>182</td>\n",
       "      <td>188</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>552</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>951</td>\n",
       "      <td>898</td>\n",
       "      <td>6.0</td>\n",
       "      <td>426</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_bet  run_id  user_id  direction_id  activity_id  size_max  size_min  \\\n",
       "0      56     790      844           3.0          358        20        10   \n",
       "1      59     135      898           6.0           29        28         5   \n",
       "2      61     182      188           2.0           42        30        12   \n",
       "3      63     182      552           3.0           42        30        12   \n",
       "4      64     951      898           6.0          426        50        10   \n",
       "\n",
       "   is_educational  is_checkin_required  activity_type_id  main_competence_id  \n",
       "0               1                    0               5.0                55.0  \n",
       "1               1                    0               5.0                21.0  \n",
       "2               1                    0               5.0                26.0  \n",
       "3               1                    0               5.0                26.0  \n",
       "4               1                    0               5.0                26.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x, y = get_data()\n",
    "print(df_x.shape)\n",
    "print(len(y))\n",
    "print(df_x.columns)\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.6000e+01 7.9000e+02 8.4400e+02 ... 0.0000e+00 5.0000e+00 5.5000e+01]\n",
      " [5.9000e+01 1.3500e+02 8.9800e+02 ... 0.0000e+00 5.0000e+00 2.1000e+01]\n",
      " [6.1000e+01 1.8200e+02 1.8800e+02 ... 0.0000e+00 5.0000e+00 2.6000e+01]\n",
      " ...\n",
      " [1.6160e+04 4.0800e+02 8.3500e+02 ... 0.0000e+00 5.0000e+00 3.3000e+01]\n",
      " [1.6161e+04 5.9600e+02 5.3600e+02 ... 0.0000e+00 6.0000e+00 3.5000e+01]\n",
      " [1.6162e+04 2.4800e+02 8.3500e+02 ... 0.0000e+00 2.0000e+00 2.0000e+01]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(df_x)\n",
    "print(x_train)\n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- user_role\n",
      "1 -- competence\n",
      "2 -- author\n",
      "3 -- time_slot\n",
      "4 -- test\n",
      "5 -- competence_level\n",
      "6 -- competence_type\n",
      "7 -- activity_track\n",
      "8 -- track\n",
      "9 -- activity_tag\n",
      "10 -- role\n",
      "11 -- train\n",
      "12 -- place\n",
      "13 -- activity_author\n",
      "14 -- event\n",
      "15 -- user_tag\n",
      "16 -- sample_submission\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим, какие есть файлы и положим их в словарь\n",
    "dfs = {}\n",
    "for i, x in enumerate(os.listdir(data_dir)):\n",
    "    file_name = x.split('.')[0]\n",
    "    print(f'{i} -- {file_name}')\n",
    "    dfs[file_name] = pd.read_csv(f'{data_dir}/{x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple prediction\n",
    "Для начала нужно попробовать самые простые модели, чтобы примерно понимать, какое качество ожидать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наивная модель, где предсказанием является среднее значение, полученное на обучающей выборке\n",
    "regr = DummyRegressor(strategy='mean')\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "# Наивная модель, где предсказанием является медиана, полученная на обучающей выборке\n",
    "# Эта статистика менее подвержена выбросам, поэтому, возможно, даст лучшее качество\n",
    "regr = DummyRegressor(strategy='median')\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "# Градиентный бустинг\n",
    "regr = xgb.XGBRegressor()\n",
    "#regr = lgb.LGBMRegressor()\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "# К средних соседей\n",
    "regr = KNeighborsRegressor()\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как ни странно, лучшее качество дал алгоритм ближайших соседей.\n",
    "\n",
    "Теперь можно попробовать поиграться с гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = xgb.XGBRegressor(n_estimators=68)\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "regr = KNeighborsRegressor(n_neighbors=4, weights='distance',  p=1)\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop outliers\n",
    "Качество улучшилось, но не сильно. Возможно, нужно что то еще придумать.\n",
    "\n",
    "Можно посмотреть на наш таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sorted(y_train)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что есть выбросы и, возможно, они мешают алгоритму уловить настоящую закономерность, поэтому можно ему помочь, удалив выбросы.\n",
    "\n",
    "Делать это можно несколькими способами, но возьмем самый простой, просто выкинем все значения которые больше 95 перцентиля. Кстати, это значение тоже можно подбирать как гиперпараметр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sorted([x for x in y_train if x < np.quantile(y_train, 0.95)])).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит уже лучше, ставки на 10000 - 40000 уже не участвуют в обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование новой выборки без выбросов\n",
    "x_train = np.array(df_x)\n",
    "y_train = np.array(y)\n",
    "\n",
    "x_train = x_train[[True if x < np.quantile(y_train, 0.95) else False for x in y_train]]\n",
    "y_train = [x for x in y_train if x < np.quantile(y_train, 0.95)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии с тем как делали выше, посмотрим качество моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наивная модель где предсказанием является среднее значение полученное на обучающей выборке\n",
    "regr = DummyRegressor(strategy='mean')\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "# Наивная модель где предсказанием является медиана полученная на обучающей выборке\n",
    "# Эта статистика менее подвержена выбросам, поэтому возможно даст лучшее качество\n",
    "regr = DummyRegressor(strategy='median')\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "# Градиентный бустинг \n",
    "regr = xgb.XGBRegressor()\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "# К средних соседей\n",
    "regr = KNeighborsRegressor()\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = xgb.XGBRegressor(n_estimators=66, num_leaves=38)\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "regr = KNeighborsRegressor(n_neighbors=4, weights='distance',  p=1)\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "Добавим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(df_x)\n",
    "y_train = np.array(y)\n",
    "\n",
    "# тут происходит мерж исходных данных и дополнительных, которые мы считали в словарь dfs\n",
    "\n",
    "df_tmp = pd.merge(df_x, dfs['activity_author'].groupby('activity_id').count().reset_index(),  \n",
    "                  how='left', \n",
    "                  left_on='activity_id', right_on='activity_id', \n",
    "                  suffixes=('_x', 'activity_author'))\n",
    "\n",
    "df_tmp = pd.merge(df_tmp, dfs['event'].groupby('run_id').count().reset_index(),  \n",
    "                  how='left', \n",
    "                  left_on='run_id', right_on='run_id', \n",
    "                  suffixes=('_x', '_event'))\n",
    "\n",
    "df_tmp = pd.merge(df_tmp, dfs['user_role'].drop_duplicates('user_id'),\n",
    "                  how='left', \n",
    "                  left_on='user_id', right_on='user_id', \n",
    "                  suffixes=('_x', '_event'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = xgb.XGBRegressor()\n",
    "regr_score(df_tmp, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "\n",
    "regr = KNeighborsRegressor(n_neighbors=4, weights='distance',  p=1)\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tmp.shape)\n",
    "print(len(y))\n",
    "\n",
    "df_tmp = df_tmp.fillna(-1)\n",
    "x_train = np.array(df_tmp)\n",
    "y_train = np.array(y)\n",
    "\n",
    "x_train = x_train[[True if x < np.quantile(y_train, 0.95) else False for x in y_train]]\n",
    "y_train = [x for x in y_train if x < np.quantile(y_train, 0.95)]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = xgb.XGBRegressor(n_estimators=60, num_leaves=39)\n",
    "regr_score(x_train, y_train, regr, rmsle)\n",
    "print()\n",
    "\n",
    "\n",
    "regr = KNeighborsRegressor(n_neighbors=4, weights='distance',  p=1)\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество не улучшилось, но это значит нужно чуть глубже капнуть в дополнительные признаки.\n",
    "\n",
    "Можно посмотреть что важно в данных по мнению бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = xgb.XGBRegressor()\n",
    "regr.fit(x_train, y_train)\n",
    "pyplot.figure(figsize=(20,10))\n",
    "pyplot.bar(df_tmp.columns, regr.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самыми важными признакми являются user_id и id_bet\n",
    "\n",
    "Можно попробовать посмотреть то же самое, заэнкодив признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Сделаем сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(df_x, dfs['activity_author'].groupby('activity_id').count().reset_index(),  \n",
    "                  how='left', \n",
    "                  left_on='activity_id', right_on='activity_id', \n",
    "                  suffixes=('_x', 'activity_author'))\n",
    "\n",
    "df_tmp = pd.merge(df_tmp, dfs['event'].groupby('run_id').count().reset_index(),  \n",
    "                  how='left', \n",
    "                  left_on='run_id', right_on='run_id', \n",
    "                  suffixes=('_x', '_event'))\n",
    "\n",
    "df_tmp = pd.merge(df_tmp, dfs['user_role'].drop_duplicates('user_id'),\n",
    "                  how='left', \n",
    "                  left_on='user_id', right_on='user_id', \n",
    "                  suffixes=('_x', '_event'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_test = pd.read_csv(f'{data_dir}/test.csv')\n",
    "df_x_test = df_x_test.fillna(-1)\n",
    "df_x_test = df_x_test.drop(['short', 'activity_title', 'title_activity_type',\n",
    "            'activity_description', 'title_direction', 'comment_direction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_bet' 'run_id' 'user_id' 'direction_id' 'activity_id' 'size_max'\n",
      " 'size_min' 'is_educational' 'is_checkin_required' 'activity_type_id'\n",
      " 'main_competence_id' 'author_id' 'id' 'place_id' 'time_slot_id' 'role_id']\n",
      "['id_bet' 'run_id' 'user_id' 'direction_id' 'activity_id' 'size_max'\n",
      " 'size_min' 'is_educational' 'is_checkin_required' 'activity_type_id'\n",
      " 'main_competence_id' 'author_id' 'id' 'place_id' 'time_slot_id' 'role_id']\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.merge(df_x_test, dfs['activity_author'].groupby('activity_id').count().reset_index(),  \n",
    "                  how='left', \n",
    "                  left_on='activity_id', right_on='activity_id', \n",
    "                  suffixes=('_x', 'activity_author'))\n",
    "\n",
    "df_test = pd.merge(df_test, dfs['event'].groupby('run_id').count().reset_index(),  \n",
    "                  how='left', \n",
    "                  left_on='run_id', right_on='run_id', \n",
    "                  suffixes=('_x', '_event'))\n",
    "\n",
    "df_test = pd.merge(df_test, dfs['user_role'].drop_duplicates('user_id'),\n",
    "                  how='left', \n",
    "                  left_on='user_id', right_on='user_id', \n",
    "                  suffixes=('_x', '_event'))\n",
    "\n",
    "print(df_tmp.columns.values)\n",
    "print(df_test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_tmp.fillna(-1)\n",
    "df_test = df_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(df_tmp)\n",
    "x_test = np.array(df_test)\n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[[True if x < np.quantile(y_train, 0.95) else False for x in y_train]]\n",
    "y_train = [x for x in y_train if x < np.quantile(y_train, 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=68,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting\n",
    "regr = xgb.XGBRegressor(n_estimators=68)\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48561553 1.73304101 1.42651735 1.6966553  1.8745859 ]\n",
      "mean score -- 1.6432830170522217\n"
     ]
    }
   ],
   "source": [
    "#Cross validation score\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.09 ms, sys: 1.52 ms, total: 7.61 ms\n",
      "Wall time: 5.89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First submit\n",
    "submit = pd.concat([df_test['id_bet'], pd.Series(test_pred)], axis=1)\n",
    "submit.columns=['id_bet', 'label']\n",
    "submit.to_csv('submit_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.39051285 1.30915951 1.5058642  1.69237008 1.80835085]\n",
      "mean score -- 1.5412514976801632\n"
     ]
    }
   ],
   "source": [
    "#Let's play with XGBoost parameters\n",
    "#Fitting\n",
    "regr = xgb.XGBRegressor(n_estimators=23, learning_rate = 0.1, max_depth = 4)\n",
    "regr.fit(x_train, y_train)\n",
    "#Cross validation score\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third submit with tuned parameters\n",
    "submit = pd.concat([df_test['id_bet'], pd.Series(test_pred)], axis=1)\n",
    "submit.columns=['id_bet', 'label']\n",
    "submit.to_csv('submit_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать фит только на отобранных градиентным бустингом признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_tmp.drop(['run_id'], axis=1, inplace=True)\n",
    "df_feature = df_tmp.iloc[:, :2]\n",
    "df_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_feature = df_test.drop(['run_id'], axis=1, inplace=True)\n",
    "df_test_feature = df_test.iloc[:, :2]\n",
    "df_test_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(df_feature)\n",
    "x_test = np.array(df_test_feature)\n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[[True if x < np.quantile(y_train, 0.95) else False for x in y_train]]\n",
    "y_train = [x for x in y_train if x < np.quantile(y_train, 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting\n",
    "regr = xgb.XGBRegressor(n_estimators=23, learning_rate = 0.1, max_depth = 4)\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation score\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка уменьшилась!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second submit with selected features\n",
    "submit = pd.concat([df_test['id_bet'], pd.Series(test_pred)], axis=1)\n",
    "submit.columns=['id_bet', 'label']\n",
    "submit.to_csv('submit_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что же получается для k - neighbors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting\n",
    "regr = KNeighborsRegressor(n_neighbors=4, weights='distance',  p=1)\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation score\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А для k-neighbors не сработало - ошибка чуть ухудшилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем оттюнить параметры для градиентного бустинга с помощью random search для отобранных фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor  \n",
    "import scipy.stats as st\n",
    "seed = 342\n",
    "np.random.seed(seed)\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 40),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "}\n",
    "\n",
    "xgbreg = XGBRegressor(nthreads=-1, seed=seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "gs = RandomizedSearchCV(xgbreg, params, scoring = rmsle, n_jobs=1, random_state = seed)  \n",
    "gs.fit(x_train, y_train)  \n",
    "gs.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = xgb.XGBRegressor(colsample_bytree = 0.97, n_estimators=23, reg_alpha = 27.21, \n",
    "                        subsample = 0.908, min_child_weight = 3.89, max_depth = 24, learning_rate = 0.26, gamma = 5.57)\n",
    "regr.fit(x_train, y_train)\n",
    "regr_score(x_train, y_train, regr, rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMIA_2018",
   "language": "python",
   "name": "dmia_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
